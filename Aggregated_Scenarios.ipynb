{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cloned_repo_path = os.path.abspath('')#insert path here\n",
    "sys.path.insert(0, cloned_repo_path)\n",
    "cloned_repo_path = os.path.abspath('.')\n",
    "sys.path.insert(0, cloned_repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64205ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle \n",
    "import stumpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9de64",
   "metadata": {},
   "source": [
    "## Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory=\"Results\"):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(\"Directory Created Successfully\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Directory Already Exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_visualize_mdls(final_data, motifs_idx, nn_idx, filepath, m=2016):\n",
    "    mdls, subspaces = stumpy.mdl(final_data, m, motifs_idx, nn_idx)\n",
    "    subspaces = [ele.tolist() for ele in subspaces]\n",
    "    \n",
    "    print(f\"Subspaces:\\n\\t {subspaces}\\n\")\n",
    "\n",
    "    k = np.argmin(mdls)\n",
    "\n",
    "    print(f\"Suugested Columns For Multidimensional Matrix Profile:\\n\\t {final_data.columns[subspaces[k]]}\\n\")\n",
    "    \n",
    "    plt.plot(np.arange(len(mdls)), mdls, c='red', linewidth='4')\n",
    "    plt.xlabel('k (zero-based)', fontsize='20')\n",
    "    plt.ylabel('Bit Size', fontsize='20')\n",
    "    plt.xticks(range(mps.shape[0]))\n",
    "    \n",
    "    plt.savefig(filepath, transparent=False, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return final_data.columns[subspaces[k]].tolist(), subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mps_calculations_mstump_m(final_data, filepath, m=2016):\n",
    "    # Calculating Multidimensional Matrix Profile For a weekly rhythm where subsequent length m=2016\n",
    "\n",
    "    mps, indices = stumpy.mstump_m(final_data, m)\n",
    "\n",
    "    # Displaying the shape of MultiDimensional Matrix Profile \n",
    "\n",
    "    print(f\"MPS Shape: {mps.shape}\")\n",
    "\n",
    "    # 1 single motif for each dimension\n",
    "\n",
    "    motifs_idx = np.argmin(mps, axis=1)   \n",
    "    print(f\"Motif Start Index: {motifs_idx}\")\n",
    "        nn_idx = indices[np.arange(len(motifs_idx)), motifs_idx]\n",
    "    \n",
    "    \n",
    "    print(f\"Nearest Start Index: {nn_idx}\")\n",
    "\n",
    "    df = final_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(mps.shape[0] * 2, sharex=True, gridspec_kw={'hspace': 0}, figsize=(25, mps.shape[0] * 5))\n",
    "    label = ''\n",
    "    for k, dim_name in enumerate(df.columns):\n",
    "        axs[k].set_ylabel(dim_name, fontsize=10)\n",
    "        axs[k].set_xlabel('Time', fontsize=10) \n",
    "        \n",
    "        axs[k].plot(df[dim_name], label=sensor_id_type_mapping[dim_name])\n",
    " \n",
    "        axs[k].legend(loc=\"upper right\")\n",
    "        \n",
    "        axs[k].plot(range(motifs_idx[k], motifs_idx[k] + m), df[dim_name].iloc[motifs_idx[k] : motifs_idx[k] + m], c='red', linewidth=4)\n",
    "        axs[k].plot(range(nn_idx[k], nn_idx[k] + m), df[dim_name].iloc[nn_idx[k] : nn_idx[k] + m], c='red', linewidth=4)\n",
    "\n",
    "        label = label + ', ' + dim_name\n",
    "        \n",
    "        axs[k].axvline(x=motifs_idx[k], linestyle=\"dashed\", c='black')\n",
    "        axs[k].axvline(x=nn_idx[k], linestyle=\"dashed\", c='black')\n",
    "\n",
    "        axs[k + mps.shape[0]].set_ylabel(f\"P_{k}\", fontsize=10)\n",
    "        axs[k + mps.shape[0]].plot(mps[k], c='orange', label=f\"{label.strip(',')}\")\n",
    "        axs[k + mps.shape[0]].set_xlabel('Time', fontsize=10)    \n",
    "\n",
    "        axs[k + mps.shape[0]].axvline(x=motifs_idx[k], linestyle=\"dashed\", c='black')\n",
    "        axs[k + mps.shape[0]].axvline(x=nn_idx[k], linestyle=\"dashed\", c='black')    \n",
    "\n",
    "        axs[k + mps.shape[0]].plot(motifs_idx[k], mps[k, motifs_idx[k]] + 1, marker=\"v\", markersize=10, color='red')\n",
    "        axs[k + mps.shape[0]].plot(nn_idx[k], mps[k, nn_idx[k]] + 1, marker=\"v\", markersize=10, color='red')\n",
    "        \n",
    "        axs[k + mps.shape[0]].text(motifs_idx[k], mps[k, motifs_idx[k]], f\"{1}m\", fontsize=\"xx-large\")\n",
    "        axs[k + mps.shape[0]].text(nn_idx[k], mps[k, motifs_idx[k]], f\"{1}n\", fontsize=\"xx-large\")\n",
    "        axs[k + mps.shape[0]].legend(loc=\"upper right\")\n",
    "        \n",
    "    plt.savefig(filepath, transparent=False, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return mps, indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564154ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "\n",
    "def get_percent_motif_start_index(motifs):\n",
    "    final_motifs = []\n",
    "    \n",
    "    for i in range(0, len(motifs), 2016):\n",
    "        final_motifs.append(motifs.index[i])\n",
    "            \n",
    "    return final_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee0196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further Processing the motifs \n",
    "\n",
    "def get_motif_start_index(motifs):\n",
    "    final_motifs = []\n",
    "    j = 0\n",
    "    check = False\n",
    "    \n",
    "    for i in range(0, len(motifs), 2016):\n",
    "        if not check:\n",
    "            j = i\n",
    "\n",
    "        final_motifs.append(motifs[j])\n",
    "\n",
    "        if check:\n",
    "            j = i + value\n",
    "\n",
    "        elif motifs[i] + 2016 > len(motifs):\n",
    "            value = len(motifs) - motifs[i]\n",
    "            j = i + value\n",
    "            check = True\n",
    "            \n",
    "                \n",
    "    return final_motifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function takes in percentage for discord and percentage for motif \n",
    "\n",
    "\n",
    "def select_motifs_discords_percentage(mps, dimension, motif_percentage, discord_percentage, motifs={}, discords={}):\n",
    "    motif_threshold = mps.quantile(motif_percentage/100)\n",
    "    discord_threshold = mps.quantile((100 - discord_percentage)/100)\n",
    "    \n",
    "    motif = mps[mps < motif_threshold]\n",
    "    discord = mps[mps > discord_threshold]\n",
    "    \n",
    "    if len(motif):\n",
    "        \n",
    "        motifs[dimension] = get_percent_motif_start_index(motif)\n",
    "        \n",
    "    return motifs, discords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d624241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the upper K of all points and lowest J \n",
    "\n",
    "def select_top_k_motifs_discords(mps, dimension, k_motifs, k_discords, motifs={}, discords={}):\n",
    "\n",
    "    sorted_mps = np.argsort(mps, kind='stable')\n",
    "    \n",
    "    motifs[dimension] = get_motif_start_index(sorted_mps)[:k_motifs]\n",
    "    \n",
    "    return motifs, discords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b52481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking user's input for function \n",
    "\n",
    "\n",
    "motif_thresholds_for_all_dimensions = {}\n",
    "\n",
    "def take_function_and_function_parameters_input():\n",
    "    motif_thresholds_for_all_dimensions = {}\n",
    "    for dimension in range(mps.shape[0]):\n",
    "        motif_thresholds_for_single_dimension = {}\n",
    "        function = input(f\"Select A Function To Be Applied to Dimension {dimension}\\n\"\n",
    "                         f\"\\tPress 1 For Selection Based on Percentage\\n \"\n",
    "                         f\"\\tPress 2 For Top K Motifs and Discords Selection: \")\n",
    "\n",
    "        if int(function) == 1:\n",
    "            motif_percentage = input(f\"\\tEnter a Specific Threshold Value For Motif Selection For Dimension {dimension}: \")\n",
    "            discord_percentage = input(f\"\\tEnter a Specific Threshold Value For Discord Selection For Dimension {dimension}: \")\n",
    "            motif_thresholds_for_single_dimension[\"function\"] = int(function)\n",
    "            motif_thresholds_for_single_dimension[\"motif_percentage\"] = int(motif_percentage)\n",
    "            motif_thresholds_for_single_dimension[\"discord_percentage\"] = int(discord_percentage)\n",
    "\n",
    "        elif int(function) == 2:\n",
    "            k_motif = input(f\"\\tEnter Top K Motif Selection For Dimension {dimension}: \")\n",
    "            k_discord = input(f\"\\tEnter Top K Discord Selection For Dimension {dimension}: \")\n",
    "            motif_thresholds_for_single_dimension[\"function\"] = int(function)\n",
    "            motif_thresholds_for_single_dimension[\"k_motifs\"] = int(k_motif)\n",
    "            motif_thresholds_for_single_dimension[\"k_discords\"] = int(k_discord)\n",
    "        else:\n",
    "            continue\n",
    "        motif_thresholds_for_all_dimensions[dimension] = motif_thresholds_for_single_dimension\n",
    "        \n",
    "    return motif_thresholds_for_all_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc Motifs and Discords \n",
    "\n",
    "\n",
    "def calculate_motifs_discords_for_each_dimension(mps, motif_thresholds_for_all_dimensions):\n",
    "    motifs = {}\n",
    "    discords = {}\n",
    "\n",
    "    mps_df = pd.DataFrame(mps).T\n",
    "\n",
    "    for key, value in motif_thresholds_for_all_dimensions.items():\n",
    "        if value.get('function') == 1:\n",
    "            motifs, discords = select_motifs_discords_percentage(mps_df[key], key, value[\"motif_percentage\"],\n",
    "                                                                 value[\"discord_percentage\"], motifs, discords)\n",
    "        elif value.get('function') == 2:\n",
    "            motifs, discords = select_top_k_motifs_discords(mps_df[key], key, value['k_motifs'], \n",
    "                                                            value['k_discords'], motifs, discords)\n",
    "    return motifs, discords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de088a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting nn that correspond to each motif_idx  \n",
    "\n",
    "def calculate_nn_and_filter_motifs(motifs):\n",
    "    final_nn = {}\n",
    "    final_motifs = {}\n",
    "\n",
    "    for key, values in motifs.items():\n",
    "        nns = {}\n",
    "        for value in values:\n",
    "            if nns.get(value) is None:\n",
    "                if final_nn.get(key):\n",
    "                    final_nn[key].append(indices[key, value])\n",
    "                    final_motifs[key].append(value)\n",
    "                else:\n",
    "                    final_nn.setdefault(key, []).append(indices[key, value])\n",
    "                    final_motifs.setdefault(key, []).append(value)\n",
    "\n",
    "                nns[indices[key, value]] = 1\n",
    "    \n",
    "    return final_motifs, final_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nns(motifs):\n",
    "    final_nn = {}\n",
    "    final_motifs = {}\n",
    "\n",
    "    for key, values in motifs.items():\n",
    "        nns = {}\n",
    "        for value in values:\n",
    "            if final_nn.get(key):\n",
    "                final_nn[key].append(indices[key, value])\n",
    "                final_motifs[key].append(value)\n",
    "            else:\n",
    "                final_nn.setdefault(key, []).append(indices[key, value])\n",
    "                final_motifs.setdefault(key, []).append(value)\n",
    "\n",
    "            nns[indices[key, value]] = 1\n",
    "    \n",
    "    return final_motifs, final_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sensor_id_type_mapping(location_input):\n",
    "    sensors_id_type = sensor_location_type_ids.loc[:,location_input].to_dict()\n",
    "\n",
    "    sensor_id_type_mapping = {}\n",
    "    for key, values in sensors_id_type.items():\n",
    "        if isinstance(values, str)  and 'list' not in key:\n",
    "            for value in eval(values.replace(' ', ',')):\n",
    "                sensor_id_type_mapping[f\"{value}\"] = key\n",
    "            \n",
    "    return sensor_id_type_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab828fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the dimens  along with mp values\n",
    "\n",
    "\n",
    "def plot_results_of_mps(df, mps, m, final_motifs, final_nn, sensor_id_type_mapping, filepath):\n",
    "    fig, axs = plt.subplots(mps.shape[0] * 2, sharex=True, gridspec_kw={'hspace': 0}, figsize=(25, mps.shape[0] * 5))\n",
    "    label = ''\n",
    "    for k, dim_name in enumerate(df.columns):\n",
    "        axs[k].set_ylabel(dim_name, fontsize=10)\n",
    "        axs[k].set_xlabel('Time', fontsize=10) \n",
    "        axs[k].plot(df[dim_name], label=sensor_id_type_mapping[dim_name])\n",
    "        axs[k].legend(loc=\"upper right\")\n",
    "        i = 0\n",
    "        if final_motifs.get(k) and final_nn.get(k):\n",
    "            for motifs_idx, nn_idx in zip(final_motifs.get(k), final_nn.get(k)):\n",
    "                \n",
    "                axs[k].plot(df[dim_name].iloc[motifs_idx : motifs_idx + m], c='red', linewidth=4)\n",
    "                axs[k].plot(df[dim_name].iloc[nn_idx : nn_idx + m], c='red', linewidth=4)\n",
    "                axs[k].axvline(x=motifs_idx, linestyle=\"dashed\", c='black')\n",
    "                axs[k].axvline(x=nn_idx, linestyle=\"dashed\", c='black')\n",
    "\n",
    "                axs[k + mps.shape[0]].plot(motifs_idx, mps[k, motifs_idx] + 1, marker=\"v\", markersize=10, color='red')\n",
    "                axs[k + mps.shape[0]].plot(nn_idx, mps[k, nn_idx] + 1, marker=\"v\", markersize=10, color='red')\n",
    "\n",
    "                axs[k + mps.shape[0]].axvline(x=motifs_idx, linestyle=\"dashed\", c='black')\n",
    "                axs[k + mps.shape[0]].axvline(x=nn_idx, linestyle=\"dashed\", c='black')\n",
    "\n",
    "                axs[k + mps.shape[0]].text(motifs_idx, mps[k][motifs_idx], f\"{i+1}m\", fontsize=\"xx-large\")\n",
    "                axs[k + mps.shape[0]].text(nn_idx, mps[k][nn_idx], f\"{i+1}n\", fontsize=\"xx-large\")\n",
    "\n",
    "                i += 1\n",
    "        label = label + ', ' + dim_name\n",
    "        \n",
    "        axs[k + mps.shape[0]].set_ylabel(f\"P_{k}\", fontsize=10)\n",
    "        axs[k + mps.shape[0]].plot(mps[k], c='orange', label=f\"{label.strip(',')}\")\n",
    "        axs[k + mps.shape[0]].set_xlabel('Time', fontsize=10)\n",
    "        axs[k + mps.shape[0]].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.savefig(filepath, transparent=False, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989534ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_functions(final_data, mps, m, filepath):\n",
    "    motif_thresholds_for_all_dimensions = take_function_and_function_parameters_input()\n",
    "\n",
    "    print(f\"\\nMotif Threshold Dictionary:\\n\\t {motif_thresholds_for_all_dimensions}\\n\")\n",
    "\n",
    "    motifs, discords = calculate_motifs_discords_for_each_dimension(mps, motif_thresholds_for_all_dimensions)\n",
    "\n",
    "\n",
    "    print(f\"Motifs Before Filtering:\\n\\t {motifs}\\n\")\n",
    "\n",
    "    final_motifs, final_nn = calculate_nn_and_filter_motifs(motifs)\n",
    "\n",
    "\n",
    "    df = final_data.reset_index(drop=True)\n",
    "\n",
    "    sensor_id_type_mapping = create_sensor_id_type_mapping(location_input)\n",
    "\n",
    "    plot_results_of_mps(df, mps, m, final_motifs, final_nn, sensor_id_type_mapping, filepath)\n",
    "    \n",
    "    return final_motifs, final_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901063e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_functions_heatmap(final_data, mps, m, filepath, sensor_id_type_mapping, \n",
    "                            motif_thresholds_for_all_dimensions):\n",
    "    \n",
    "\n",
    "    print(f\"\\nMotif Threshold Dictionary:\\n\\t {motif_thresholds_for_all_dimensions}\\n\")\n",
    "\n",
    "    motifs, discords = calculate_motifs_discords_for_each_dimension(mps, motif_thresholds_for_all_dimensions)\n",
    "\n",
    "    print(f\"Motifs Before Filtering:\\n\\t {motifs}\\n\")\n",
    "\n",
    "    final_motifs, final_nn = calculate_nns(motifs)\n",
    "\n",
    "\n",
    "    df = final_data.reset_index(drop=True)\n",
    "\n",
    "    plot_results_of_mps(df, mps, m, final_motifs, final_nn, sensor_id_type_mapping, filepath)\n",
    "    \n",
    "    return final_motifs, final_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_json_subspaces(final_data, mps, m, filepath, json_path, sensor_id_type_mapping,\n",
    "                         motif_thresholds_for_all_dimensions, sensor_type_id, device_type_id):\n",
    "    \n",
    "    final_motifs, final_nn = apply_functions_heatmap(final_data, mps, 2016, filepath, sensor_id_type_mapping, \n",
    "                                                    motif_thresholds_for_all_dimensions)\n",
    "\n",
    "    # Creating a list of dictionaries that will be dumped to json file\n",
    "        # (\"motif_id\",\"motif_idx\", \"nn_idx\",\"subspace_column\", \"subspace_sensor_ids\")\n",
    "\n",
    "    json_data = []\n",
    "\n",
    "    for k in range(final_data.shape[1]):\n",
    "        values = {'k': k}\n",
    "        i = 1\n",
    "        subspaces = []\n",
    "        \n",
    "        if final_motifs and final_motifs.get(k):\n",
    "            \n",
    "            for motifs_idx, nn_idx in zip(final_motifs[k], final_nn[k]):\n",
    "                subspace = stumpy.subspace(final_data, 2016, motifs_idx, nn_idx, k)\n",
    "                motif_subspaces = {\"motif_id\": i, \"motif_idx\": int(motifs_idx), \n",
    "                                   \"nn_idx\": int(nn_idx), \"subspace_column\": subspace.tolist(), \n",
    "                                   \"subspace_sensor_ids\": final_data.columns[subspace].tolist(),\n",
    "                                  \"subspace_sensor_types\": sensor_type_id[final_data.columns[subspace].tolist()].values.tolist()[0],\n",
    "                                  \"subspace_device_types\": device_type_id[final_data.columns[subspace].tolist()].values.tolist()[0]}\n",
    "                i += 1\n",
    "                \n",
    "                print(f\"For k = {k}, the {k + 1}-dimensional subspace includes subsequences from {subspace}\")\n",
    "                subspaces.append(motif_subspaces)\n",
    "        \n",
    "        values['motif_subspaces'] = subspaces\n",
    "        json_data.append(values)\n",
    "\n",
    "        # Dumping the motifs and nearest neighbors  \n",
    " \n",
    "\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mdl_json(final_data, final_subspaces, json_path, sensor_type_id, device_type_id):\n",
    "    final_subspaces = pd.DataFrame(final_subspaces).T\n",
    "    json_data = []\n",
    "    for i in range(final_subspaces.shape[1]):\n",
    "        motif_id = 1 \n",
    "        values = {'k': i}\n",
    "        motif_subspaces = []\n",
    "\n",
    "        for subspace in final_subspaces[i]:\n",
    "            single_motif = {\"motif_id\": motif_id, \"subspace_column\": subspace, \n",
    "                           \"subspace_sensor_ids\": final_data.columns[subspace].tolist(),\n",
    "                            \"subspace_sensor_types\": sensor_type_id[final_data.columns[subspace].tolist()].values.tolist()[0],\n",
    "                            \"subspace_device_types\": device_type_id[final_data.columns[subspace].tolist()].values.tolist()[0]}\n",
    "            motif_id += 1\n",
    "            motif_subspaces.append(single_motif)\n",
    "\n",
    "        values[\"motif_subspaces\"] = motif_subspaces\n",
    "        json_data.append(values)\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1910db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_motifs_subspaces_function(final_data, mps, sensor_type_id, \n",
    "                                    device_type_id, threshold_input, sensor_id_type_mapping,\n",
    "                                    image_path, m=2016):\n",
    "    \n",
    "    for i in range(0, int(threshold_input)):\n",
    "        motif_thresholds_for_all_dimensions = {}\n",
    "        motif_thresholds_for_single_dimension = {}\n",
    "        \n",
    "        for dimension in range(final_data.shape[1]):\n",
    "            motif_thresholds_for_single_dimension[\"function\"] = 2\n",
    "            motif_thresholds_for_single_dimension[\"k_motifs\"] = i+1\n",
    "            motif_thresholds_for_single_dimension[\"k_discords\"] = i+1\n",
    "            motif_thresholds_for_all_dimensions[dimension] = motif_thresholds_for_single_dimension\n",
    "\n",
    "        build_json_subspaces(final_data, mps, m, \n",
    "                             f\"{image_path}//All_Dimensions_mstump_m_Weekly_Top_{i}_motifs.jpg\", \n",
    "                             f\"{image_path}//Subspaces_Data_Weekly_Top_{i}_motifs.json\", sensor_id_type_mapping,\n",
    "                             motif_thresholds_for_all_dimensions, sensor_type_id, device_type_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9261266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_motifs_mdl_function(final_data, mps, sensor_type_id, device_type_id, \n",
    "                              threshold_input, mdls_path, m=2016):\n",
    "    \n",
    "    for i in range(int(threshold_input)):\n",
    "        motif_thresholds_for_all_dimensions = {}\n",
    "        motif_thresholds_for_single_dimension = {}\n",
    "        \n",
    "        for dimension in range(final_data.shape[1]):\n",
    "            motif_thresholds_for_single_dimension[\"function\"] = 2\n",
    "            motif_thresholds_for_single_dimension[\"k_motifs\"] = i+1\n",
    "            motif_thresholds_for_single_dimension[\"k_discords\"] = i+1\n",
    "            motif_thresholds_for_all_dimensions[dimension] = motif_thresholds_for_single_dimension\n",
    "\n",
    "\n",
    "        motifs, discords = calculate_motifs_discords_for_each_dimension(mps, motif_thresholds_for_all_dimensions)\n",
    "\n",
    "        final_motifs, final_nn = calculate_nns(motifs)\n",
    "\n",
    "        final_motifs = pd.DataFrame(final_motifs).T\n",
    "        final_nns = pd.DataFrame(final_nn).T\n",
    "\n",
    "        final_subspaces = {}\n",
    "        \n",
    "        for j in range(i+1):\n",
    "            columns, subspaces = calculate_and_visualize_mdls(final_data, final_motifs[j], final_nns[j],\n",
    "                                                              f\"{mdls_path}/Ideal_Dimensions_Motif_{j}.jpg\", m)\n",
    "            final_subspaces[j] = subspaces\n",
    "\n",
    "        build_mdl_json(final_data, final_subspaces, \n",
    "                       f\"{mdls_path}/MDL_Weekly_Top_{i}_motifs.json\", \n",
    "                       sensor_type_id, device_type_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671779be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_changed_subspaces(motif_subspaces, sort=False):\n",
    "    change_count = 0\n",
    "    if not motif_subspaces:\n",
    "        return None\n",
    "    \n",
    "    dataframe = []\n",
    "    \n",
    "    for subspace in motif_subspaces:\n",
    "        if sort:\n",
    "            dataframe.append({\"subspaces\": \"\".join(sorted(subspace[\"subspace_sensor_ids\"]))})\n",
    "        else:\n",
    "            dataframe.append({\"subspaces\": \"\".join(subspace[\"subspace_sensor_ids\"])})\n",
    "    \n",
    "    dataframe = pd.DataFrame(dataframe)\n",
    "    \n",
    "    return dataframe[\"subspaces\"].nunique()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_change_count(filespath):\n",
    "    files = sorted(glob.glob(filespath))\n",
    "    motif_count = 0\n",
    "    dimensions_change_count_motifs = []\n",
    "\n",
    "    for file in files:\n",
    "        motif_count += 1\n",
    "        with open(file, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        dimensions_change_count = {}\n",
    "        highest = 0\n",
    "\n",
    "        for value in json_data:\n",
    "            dimensions_change_count[value['k']] = {\"Total_Motifs\": motif_count, \n",
    "                                                   \"Changed_Count\": count_changed_subspaces(value[\"motif_subspaces\"])}\n",
    "\n",
    "        dimensions_change_count_motifs.append(dimensions_change_count)    \n",
    "\n",
    "\n",
    "    matrix = np.nan * np.ones(shape=(len(dimensions_change_count_motifs), len(dimensions_change_count_motifs[0])))\n",
    "\n",
    "    for i in range(len(dimensions_change_count_motifs)):\n",
    "        for key, value in dimensions_change_count_motifs[i].items():\n",
    "            matrix[i][key] = (value[\"Changed_Count\"]/value[\"Total_Motifs\"])\n",
    "\n",
    "    df = pd.DataFrame(matrix)\n",
    "    \n",
    "    return df, dimensions_change_count_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc910da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, filepath, dimensions_change_count_motifs):\n",
    "    fig, ax = plt.subplots(figsize=(len(dimensions_change_count_motifs[0]), len(dimensions_change_count_motifs)))\n",
    "    hm = sns.heatmap(data = df, annot=True, linewidths=2, ax=ax, cmap='crest')\n",
    "    hm.set(xlabel='k', ylabel='Motifs_Count')\n",
    "    ax.invert_yaxis()\n",
    "    plt.savefig(filepath, transparent=False, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff2b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_change_count_and_build_heatmap(jsons_path, heatmap_path):\n",
    "    df, dimensions_change_count_motifs = calculate_change_count(jsons_path)\n",
    "    create_heatmap(df, heatmap_path, dimensions_change_count_motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_subspace_mdl(subspace_motifs, mdl_motifs):\n",
    "    changed_count = 0\n",
    "    for subspace_motif, mdl_motif in zip(subspace_motifs, mdl_motifs):\n",
    "        if subspace_motif[\"subspace_sensor_ids\"] != mdl_motif[\"subspace_sensor_ids\"]:\n",
    "            changed_count += 1\n",
    "    return changed_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_subspaces_with_mdl_heatmap(subspaces_directory, mdls_directory):\n",
    "    dimensions_change_count_motifs = []\n",
    "    for i in range(int(threshold_input)):\n",
    "        subspace_file = f\"{subspaces_directory}/Subspaces_Data_Weekly_Top_{i}_motifs.json\"\n",
    "        mdl_file = f\"{mdls_directory}/MDL_Weekly_Top_{i}_motifs.json\"\n",
    "        \n",
    "        with open(subspace_file, 'r') as f:\n",
    "            subspace_json = json.load(f)\n",
    "        with open(mdl_file, 'r') as f:\n",
    "            mdl_json = json.load(f)\n",
    "        \n",
    "        dimensions_change_count = {}\n",
    "        \n",
    "        for subspace_value, mdl_value in zip(subspace_json, mdl_json):\n",
    "            changed_count = compare_subspace_mdl(subspace_value[\"motif_subspaces\"], mdl_value[\"motif_subspaces\"])\n",
    "            total_count = len(subspace_value[\"motif_subspaces\"])\n",
    "            dimensions_change_count[subspace_value['k']] = {\"Total_Motifs\": total_count, \"Changed_Count\": changed_count}\n",
    "        \n",
    "        dimensions_change_count_motifs.append(dimensions_change_count)\n",
    "    \n",
    "    matrix = np.nan * np.ones(shape=(len(dimensions_change_count_motifs), len(dimensions_change_count_motifs[0])))\n",
    "\n",
    "    for i in range(len(dimensions_change_count_motifs)):\n",
    "        for key, value in dimensions_change_count_motifs[i].items():\n",
    "            matrix[i][key] = (value[\"Changed_Count\"]/value[\"Total_Motifs\"])\n",
    "\n",
    "    df = pd.DataFrame(matrix)\n",
    "    \n",
    "    return df, dimensions_change_count_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_from_json_for_heatmap(motif_subspaces, column, sort=False):\n",
    "    change_count = 0\n",
    "    if not motif_subspaces:\n",
    "        return None\n",
    "    \n",
    "    string_data = []\n",
    "    \n",
    "    for subspace in motif_subspaces:\n",
    "        string_data.append(subspace[column]) \n",
    "    \n",
    "    return string_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31501357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_heatmap_subspaces_column(filespath, column):\n",
    "    files = sorted(glob.glob(filespath))\n",
    "    motif_count = 0\n",
    "    dimensions_change_count_motifs = []\n",
    "\n",
    "    for file in files:\n",
    "        motif_count += 1\n",
    "        with open(file, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        dimensions_change_count = {}\n",
    "        highest = 0\n",
    "\n",
    "        for value in json_data:\n",
    "            dimensions_change_count[value['k']] = {\"Changed_Count\": get_column_from_json_for_heatmap(value[\"motif_subspaces\"], column)}\n",
    "\n",
    "        dimensions_change_count_motifs.append(dimensions_change_count)    \n",
    "\n",
    "    matrix = np.nan * np.ones(shape=(len(dimensions_change_count_motifs), len(dimensions_change_count_motifs[0])))\n",
    "    matrix = [[0]*len(dimensions_change_count_motifs[0]) for i in range(len(dimensions_change_count_motifs))]\n",
    "    for i in range(len(dimensions_change_count_motifs)):\n",
    "        for key, value in dimensions_change_count_motifs[i].items():\n",
    "            matrix[i][key] = value[\"Changed_Count\"]\n",
    "\n",
    "    df = pd.DataFrame(matrix)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_csvs_for_subspaces_heatmap(subspaces_path, output_path, column):\n",
    "    sensor_ids_df = build_heatmap_subspaces_column(subspaces_path, column)                                                       \n",
    "\n",
    "    sensor_ids_df = sensor_ids_df.reindex(index=sensor_ids_df.index[::-1])\n",
    "\n",
    "    sensor_ids_df.index.names = ['Motifs_Count']\n",
    "\n",
    "    sensor_ids_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_dimensions(df, filepath, sensor_id_type_mapping):\n",
    "    fig, axs = plt.subplots(df.shape[1], sharex=True, gridspec_kw={'hspace': 0}, figsize=(25, df.shape[1] * 5))\n",
    "    for k, dim_name in enumerate(df.columns):\n",
    "        axs[k].set_ylabel(dim_name, fontsize=10)\n",
    "        axs[k].set_xlabel('Time', fontsize=10) \n",
    "        axs[k].plot(df[dim_name], label=sensor_id_type_mapping[dim_name])\n",
    "        axs[k].legend(loc=\"upper right\")\n",
    "                \n",
    "    plt.savefig(filepath, transparent=False, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4289ea9",
   "metadata": {},
   "source": [
    "## Creating Folders and Reading Preprocessed Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1181d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directory(directory=\"Results_Subspaces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_location_type_ids = pd.read_csv('./Processed_Data/Sensor_Location_Type_Ids.csv', index_col='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Dictionary of sensor names \n",
    "with open('./Processed_Data/sensor_type_names_dict.pkl', 'rb') as f:\n",
    "    sensor_type_names_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff385e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "location_input = input(\"Enter a Specific Location For MMP: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89113e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Results_Subspaces/\" + location_input.replace('/', '_')\n",
    "create_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6458d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subspaces_directory = directory + \"/Subspaces\"\n",
    "create_directory(subspaces_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e16d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_subspaces_directory = subspaces_directory + \"/Aggregated\"\n",
    "create_directory(aggregated_subspaces_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad139ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls_directory = directory + \"/MDLs\"\n",
    "create_directory(mdls_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd3f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_mdls_directory = mdls_directory + \"/Aggregated\"\n",
    "create_directory(aggregated_mdls_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5af2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of sensor_ids/columns\n",
    "\n",
    "columns = []\n",
    "bool_columns = []\n",
    "decimal_columns = []\n",
    "\n",
    "for key in sensor_type_names_dict.keys():\n",
    "    if key == 'bool':\n",
    "        bool_columns.extend(eval(sensor_location_type_ids.loc[f'{key}_list', location_input]))\n",
    "    elif key == 'decimal':\n",
    "        decimal_columns.extend(eval(sensor_location_type_ids.loc[f'{key}_list', location_input]))   \n",
    "    columns.extend(eval(sensor_location_type_ids.loc[f'{key}_list', location_input]))\n",
    "    \n",
    "columns.append('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_type_id = {}\n",
    "for column in decimal_columns:\n",
    "    sensor_type_id[column] = \"decimal\"\n",
    "for column in bool_columns:\n",
    "    sensor_type_id[column] = \"bool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c16660",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv(\"./Processed_Data/Final_Sensor_Time_Series_Imputed.csv\", usecols=columns, \n",
    "                         index_col='Timestamp', parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1007a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbaa529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping of Sensor id to Device Type \n",
    "\n",
    "sensors_id_type = sensor_location_type_ids.loc[:,location_input].to_dict()\n",
    "\n",
    "sensor_id_type_mapping = {}\n",
    "for key, values in sensors_id_type.items():\n",
    "    if isinstance(values, str)  and 'list' not in key:\n",
    "        for value in eval(values.replace(' ', ',')):\n",
    "            sensor_id_type_mapping[f\"{value}\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554261d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sensor_id_type_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473824e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_all_dimensions(final_data, f\"{directory}/All_Dimensions.jpg\", sensor_id_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_choice = input(\"Do You Want Filter Specific Columns to be used for MMP Calculation\"\n",
    "                      \"\\n\\t Press 1 to Select the Columns\"\n",
    "                      \"\\n\\t Press Any Other Key to Use All the Columns (No Filtering):\\n\")\n",
    "\n",
    "new_final_data = final_data.copy()\n",
    "\n",
    "if select_choice == '1':\n",
    "    select_dimensions = input(\"Enter Comma Separated Sensor Ids to be used for MMP Calculation: \")\n",
    "    columns_to_use = select_dimensions.split(',')\n",
    "    columns_to_use = [value.strip() for value in columns_to_use]\n",
    "    \n",
    "    new_final_data = final_data[columns_to_use]\n",
    "    plot_all_dimensions(new_final_data, f\"{directory}/After_Filtering_Dimensions.jpg\", sensor_id_type_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359abe5",
   "metadata": {},
   "source": [
    "## Select The Columns Which Need to be Aggregated Using Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78482535",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_choice_mean = input(\"Do You Want to Calculate Mean over Specific Selection of Columns\"\n",
    "                      \"\\n\\t Press 1 to Select the Columns to Calculate Mean\"\n",
    "                      \"\\n\\t Press Any Other Key For No Mean:\\n\")\n",
    "\n",
    "mean_column_pairs = {}\n",
    "i = 1\n",
    "\n",
    "while select_choice_mean == '1':\n",
    "    select_dimensions_mean = input(\"Enter Comma Separated Sensor Ids to Calculate Mean: \")\n",
    "    \n",
    "    columns_for_mean = select_dimensions_mean.split(',')\n",
    "    columns_for_mean = [value.strip() for value in columns_for_mean]\n",
    "    \n",
    "    mean_column_pairs[f'Mean_{i}'] = columns_for_mean\n",
    "    sensor_id_type_mapping[f'Mean_{i}'] = select_dimensions_mean\n",
    "    sensor_type_id[f\"Mean_{i}\"] = f\"Mean Aggregated {i}\"\n",
    "    \n",
    "    select_choice_mean = input(\"Do You Want to Calculate Mean for Some Other Selection of Columns\"\n",
    "                      \"\\n\\t Press 1 to Select the Columns to Calculate Mean\"\n",
    "                      \"\\n\\t Press Any Other Key For No More Mean Calculation:\\n\")\n",
    "    i += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mean_column_pairs:\n",
    "    mean_columns = []\n",
    "\n",
    "    for key, value in mean_column_pairs.items():\n",
    "        new_final_data[key] = final_data[value].mean(axis=1)\n",
    "        mean_columns.extend(value)\n",
    "\n",
    "    new_final_data = new_final_data[list(set(new_final_data.columns) - set(mean_columns))]\n",
    "    plot_all_dimensions(new_final_data, f\"{directory}/After_Applying_Mean_Aggregation_to_Dimensions.jpg\", sensor_id_type_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0eee5",
   "metadata": {},
   "source": [
    "## Select The Columns Which Need to be Aggregated Using Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f12a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_choice_sum = input(\"Do You Want to Calculate Sum over Specific Selection of Columns\"\n",
    "                      \"\\n\\t Press 1 to Select the Columns to Calculate Sum\"\n",
    "                      \"\\n\\t Press Any Other Key For No Sum:\\n\")\n",
    "\n",
    "sum_column_pairs = {}\n",
    "i = 1\n",
    "\n",
    "while select_choice_sum == '1':\n",
    "    select_dimensions_sum = input(\"Enter Comma Separated Sensor Ids to Calculate Sum: \")\n",
    "    \n",
    "    columns_for_sum = select_dimensions_sum.split(',')\n",
    "    columns_for_sum = [value.strip() for value in columns_for_sum]\n",
    "    \n",
    "    sum_column_pairs[f'Sum_{i}'] = columns_for_sum\n",
    "    sensor_id_type_mapping[f'Sum_{i}'] = select_dimensions_sum\n",
    "    sensor_type_id[f\"Sum_{i}\"] = f\"Sum Aggregated {i}\"\n",
    "    \n",
    "    select_choice_sum = input(\"Do You Want to Calculate Sum for Some Other Selection of Columns\"\n",
    "                      \"\\n\\t Press 1 to Select the Columns to Calculate Sum\"\n",
    "                      \"\\n\\t Press Any Other Key For No More Sum Calculation:\\n\")\n",
    "        \n",
    "    i += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e12153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if sum_column_pairs:\n",
    "    sum_columns = []\n",
    "\n",
    "    for key, value in sum_column_pairs.items():\n",
    "        new_final_data[key] = final_data[value].sum(axis=1)\n",
    "        sum_columns.extend(value)\n",
    "\n",
    "    new_final_data = new_final_data[list(set(new_final_data.columns) - set(sum_columns))]\n",
    "    plot_all_dimensions(new_final_data, f\"{directory}/After_Applying_Sum_Aggregation_to_Dimensions.jpg\", sensor_id_type_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf57cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type_id = pd.DataFrame([sensor_id_type_mapping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_type_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d028867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_type_id = pd.DataFrame([sensor_type_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c398c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_data.to_csv(f\"{directory}/Aggregated_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89f89e",
   "metadata": {},
   "source": [
    "### MPS Calculation Using Constraint Algorithm For Aggregated Dimensions (Weekly Rhythm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55557cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps, indices = mps_calculations_mstump_m(new_final_data, \n",
    "                                         f\"{directory}/Aggregated_Dimensions_mstump_m_Weekly.jpg\", \n",
    "                                         m=2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4109721",
   "metadata": {},
   "source": [
    "### Applying Subspaces Function For Aggregated Dimensions With Top K Motifs (Weekly Rhythm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_input = input(\"How Many Times Do you want to select Top K Motifs (Build Json Data): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_motifs_subspaces_function(new_final_data, mps, sensor_type_id, \n",
    "                                    device_type_id, threshold_input, sensor_id_type_mapping,\n",
    "                                f\"{aggregated_subspaces_directory}\", m=2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f25a866",
   "metadata": {},
   "source": [
    "### Applying MDL Function For Aggregated Dimensions With Top K Motifs (Weekly Rhythm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbf2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_motifs_mdl_function(new_final_data, mps, sensor_type_id, device_type_id, \n",
    "                          threshold_input, f\"{aggregated_mdls_directory}\", m=2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ef7d9",
   "metadata": {},
   "source": [
    "### Calculating the Change in the Subspaces Using Subspaces Function For Aggregated Dimensions and Building a Heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5db0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_change_count_and_build_heatmap(f\"{aggregated_subspaces_directory}/*.json\", \n",
    "                                         f\"{aggregated_subspaces_directory}/heatmap.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9759f7",
   "metadata": {},
   "source": [
    "### Calculating the Change in the Subspaces Using MDL Function For Aggregated Dimensions and Building a Heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_change_count_and_build_heatmap(f\"{aggregated_mdls_directory}/*.json\", \n",
    "                                         f\"{aggregated_mdls_directory}/heatmap.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd1886",
   "metadata": {},
   "source": [
    "### Comparison Between Subspaces of MDL and Subspaces Function For Aggregated Dimensions and Building a Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc176245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, dimensions_change_count_motifs = compare_subspaces_with_mdl_heatmap(f\"{aggregated_subspaces_directory}\", \n",
    "                                                                        f\"{aggregated_mdls_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_heatmap(df, f\"{directory}/Aggregated_Subspaces_vs_MDL_heatmap.jpg\", dimensions_change_count_motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fcd634",
   "metadata": {},
   "source": [
    "### Getting Sensor_Ids For Each Quadrant of the Heatmap For Aggregated Diemsnions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"subspace_sensor_ids\"\n",
    "different_csvs_for_subspaces_heatmap(f\"{aggregated_subspaces_directory}/*.json\", \n",
    "                                     f\"{aggregated_subspaces_directory}/heatmap_{column}.csv\",\n",
    "                                     column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e143f58",
   "metadata": {},
   "source": [
    "### Getting Sensor_Types For Each Quadrant of the Heatmap For Aggregated Diemsnions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbab146",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"subspace_sensor_types\"\n",
    "different_csvs_for_subspaces_heatmap(f\"{aggregated_subspaces_directory}/*.json\",\n",
    "                                     f\"{aggregated_subspaces_directory}/heatmap_{column}.csv\",\n",
    "                                     column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df9997",
   "metadata": {},
   "source": [
    "### Getting Device_Types For Each Quadrant of the Heatmap For Aggregated Diemsnions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"subspace_device_types\"\n",
    "different_csvs_for_subspaces_heatmap(f\"{aggregated_subspaces_directory}/*.json\",\n",
    "                                     f\"{aggregated_subspaces_directory}/heatmap_{column}.csv\",\n",
    "                                     column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
